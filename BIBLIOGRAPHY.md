| **Scenario**                                                        | **Supporting paper(s) that show the relevant failure mode**                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Contractual Penalty / Arithmetic & cap + interest logic**         | *“The Validation Gap: A Mechanistic Analysis of How Language Models Compute Arithmetic but Fail to Validate It”* (2025) — shows that LLMs often compute arithmetic but fail to validate or self-check their results, leading to errors even in simple math. ([arXiv][1]) <br> *“Large Language Models and Mathematical Reasoning Failures”* (2025) — documents arithmetic, spatial reasoning, and multi-step deduction failures in LLMs. ([arXiv][2])            |
| **Tax Calculation (progressive brackets + surcharge)**              | *“Evaluating LLMs Ability to Handle Mistakes in Reasoning”* (2024) — shows that LLMs struggle to detect and correct mistakes in multi-step math reasoning, which is directly relevant to bracketed tax logic. ([arXiv][3]) <br> *“Generalizing from Errors for LLMs Mathematical Reasoning”* (ACL 2025) — discusses common error patterns in mathematical reasoning and how training methods address them. ([ACL Anthology][4])                                  |
| **Voting Validation (threshold logic, conditional rules)**          | *“Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs”* (ICML 2025) — shows that complex reasoning chains are brittle and that step dependencies are hard to verify, meaning LLMs can misapply conditional logic. ([OpenReview][5])                                                                                                                                                                                      |
| **Waterfall Distribution (priority + allocation logic)**            | *“A Survey on Reasoning Agentic Retrieval-Augmented”* (2025) — discusses how modular tool/agent architectures help with structured reasoning, implicitly showing that naive retrieval + generation struggles on complex multi-step logic. ([arXiv][6]) <br> *“Optimizing LLM Agents for Tool Usage via Contrastive Reasoning”* (2024) — shows that LLM agents using tools outperform standard LLM-only methods in complex reasoning tasks. ([papers.nips.cc][7]) |
| **Housing Grant Eligibility (conditional rules + cross-checks)**    | *“ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models”* (2023) — presents a modular approach to separate reasoning from data observation (i.e. conditional checks), implicitly showing that intertwined logic + retrieval is challenging for vanilla LMs. ([arXiv][8])                                                                                                                                                         |
| **Complex Multi-Tool Scenario (chaining many domains & rule sets)** | *“Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning”* (2025) — shows how training an LLM to orchestrate multi-turn retrieval + reasoning improves performance, implying that naive RAG or reasoning fails in multi-step scenarios. ([arXiv][9]) <br> *“The Validation Gap”* (2025) again is relevant: it shows that LLMs have systemic issues validating their own outputs when chaining reasoning. ([arXiv][1])        |

[1]: https://arxiv.org/abs/2502.11771?utm_source=chatgpt.com "The Validation Gap: A Mechanistic Analysis of How Language Models Compute Arithmetic but Fail to Validate It"
[2]: https://arxiv.org/html/2502.11574v1?utm_source=chatgpt.com "Large Language Models and Mathematical Reasoning ..."
[3]: https://arxiv.org/html/2406.10834v1?utm_source=chatgpt.com "Evaluating LLMs Ability to Handle Mistakes in ..."
[4]: https://aclanthology.org/2025.acl-long.417.pdf?utm_source=chatgpt.com "Generalizing from Errors for LLMs Mathematical Reasoning"
[5]: https://openreview.net/forum?id=4tYckHNVXV&noteId=BZC0Gus8JP&utm_source=chatgpt.com "Premise-Augmented Reasoning Chains Improve Error ..."
[6]: https://arxiv.org/html/2506.10408v1?utm_source=chatgpt.com "A Survey on Reasoning Agentic Retrieval-Augmented ..."
[7]: https://papers.nips.cc/paper_files/paper/2024/file/2db8ce969b000fe0b3fb172490c33ce8-Paper-Conference.pdf?utm_source=chatgpt.com "Optimizing LLM Agents for Tool Usage via Contrastive ..."
[8]: https://arxiv.org/abs/2305.18323?utm_source=chatgpt.com "ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models"
[9]: https://arxiv.org/abs/2503.09516?utm_source=chatgpt.com "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning"


| **Scenario**                                                                            | **RAG-only**                                                                                                                   | **SLM + MCP Agentic**                                                                                                            | **Relevant Studies (Arithmetic / Numeric Reasoning)**                                                                                                                                                                                                                                                                                                                                                                |
| --------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Contractual Penalty**<br>*(daily rate × days, caps, interest)*                        | Retrieves the correct rules but relies on the LM to perform multi-step calculations → frequent arithmetic/threshold errors.    | Uses a deterministic function (`calc_penalty`) to compute daily penalty, apply caps, and add interest accurately.                | **Number Cookbook: Number Understanding of Language Models and How to Improve It** — shows LLM fragility with numeric tasks.<br>**How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs** — numeric precision drops with longer numbers.<br>**Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures** — arithmetic often fails when numbers grow or patterns shift. |
| **Tax Calculation**<br>*(progressive brackets + surcharge)*                             | Retrieves tax brackets and surcharge rule, but model often miscalculates bracket transitions or improperly adds the surcharge. | `calc_tax` applies bracket logic and surcharge formula deterministically.                                                        | **Number Cookbook** (numeric task failures).<br>**Numerical Precision and Mathematical Reasoning** (large-number degradation).<br>**Unraveling Arithmetic in LLMs** (non-generalizable arithmetic).                                                                                                                                                                                                                  |
| **Voting Validation**<br>*(turnout threshold + approval threshold)*                     | Retrieves rules but LM commonly misapplies percentage comparisons or confuses thresholds.                                      | `check_voting` enforces turnout and approval thresholds via strict conditional logic.                                            | *(Not primarily arithmetic-intensive; included only where numeric comparison matters)*<br>**Number Cookbook** — numeric comparison errors.                                                                                                                                                                                                                                                                           |
| **Waterfall Distributions**<br>*(priority allocation of multi-million amounts)*         | Retrieves priority rules but struggles with multi-step allocations and large-number arithmetic.                                | `distribute_waterfall` enforces strict priority and performs high-value numeric allocations with no calculation drift.           | **Number Cookbook** (multi-step numeric limits).<br>**Numerical Precision and Mathematical Reasoning** (large numeric values degrade accuracy).<br>**Unraveling Arithmetic in LLMs** (pattern-based rather than rule-based arithmetic → fails in financial allocations).                                                                                                                                             |
| **Housing Grant Eligibility**<br>*(income ceilings, adjusted thresholds)*               | Retrieves criteria but LM tends to misapply percentage-based adjustments or fails edge cases.                                  | `check_housing_grant` deterministically applies income ceiling, adjusts for family size, and enforces exclusivity.               | **Number Cookbook** — percentage comparison errors.                                                                                                                                                                                                                                                                                                                                                                  |
| **Complex Multi-Tool Scenario**<br>*(tax + penalty + voting + waterfall + eligibility)* | Retrieves all relevant policies but fails to chain multi-domain calculations; arithmetic errors compound.                      | LLM orchestrates multiple deterministic tools (penalty, tax, waterfall, voting, eligibility) ensuring correctness at every step. | **Number Cookbook** (multi-operation fragility).<br>**Numerical Precision Affects Mathematical Reasoning** (cascading accuracy loss).<br>**Unraveling Arithmetic in LLMs** (explains why chained multi-step calculations fail).                                                                                                                                                                                      |
